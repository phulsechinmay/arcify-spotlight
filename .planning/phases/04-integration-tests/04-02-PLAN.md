---
phase: 04-integration-tests
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - test/integration/message-passing.test.js
  - test/integration/activation-flow.test.js
autonomous: true

must_haves:
  truths:
    - "Search query from overlay reaches background and triggers search"
    - "Search results return to overlay in expected format"
    - "Tab actions call correct Chrome APIs (tabs.update, tabs.create)"
    - "Activation sequence (inject -> activate -> ready) completes"
    - "Error scenarios return graceful error responses"
  artifacts:
    - path: "test/integration/message-passing.test.js"
      provides: "Search and result message flow tests"
      min_lines: 100
    - path: "test/integration/activation-flow.test.js"
      provides: "Spotlight activation sequence tests"
      min_lines: 50
  key_links:
    - from: "test/integration/message-passing.test.js"
      to: "background.js"
      via: "dynamic import in beforeEach"
      pattern: "await import.*background.js"
    - from: "test/integration/message-passing.test.js"
      to: "test/mocks/chrome.js"
      via: "callListeners to trigger handlers"
      pattern: "callListeners"
---

<objective>
Create integration tests for message passing flows (INT-01, INT-02) and activation sequence (INT-03).

Purpose: Verify that messages flow correctly between content scripts and background script, covering search queries, result delivery, tab actions, and the spotlight activation lifecycle.

Output: Comprehensive integration tests in test/integration/ covering all message types identified in research.
</objective>

<execution_context>
@/Users/phulsechinmay/.claude/get-shit-done/workflows/execute-plan.md
@/Users/phulsechinmay/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-integration-tests/04-RESEARCH.md
@.planning/phases/04-integration-tests/04-01-SUMMARY.md

# Source files being tested
@background.js
@shared/search-types.js

# Test infrastructure
@test/mocks/chrome.js
@test/integration/setup.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create message passing integration tests</name>
  <files>test/integration/message-passing.test.js</files>
  <action>
Create test/integration/message-passing.test.js covering INT-01 and INT-02:

**Test Structure:**
```javascript
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { chromeMock, resetChromeMocks } from '../mocks/chrome.js';

// Import setup for side effects (real timers, global chrome)
import './setup.js';
```

**Test Groups (use describe blocks):**

1. **SPOTLIGHT_SEARCH (getSpotlightSuggestions)** - covers INT-01
   - `query flows from overlay to background and returns results` - full round-trip test
   - `verifies SearchEngine is called with correct parameters` - query trimming, mode passed
   - `empty query returns results without debounce` - immediate response path
   - `handles search with no matches` - empty results array

2. **Result Delivery (spotlightHandleResult)** - covers INT-02
   - `URL_SUGGESTION in NEW_TAB mode calls chrome.tabs.create`
   - `URL_SUGGESTION in CURRENT_TAB mode calls chrome.tabs.update with sender.tab.id`
   - `TAB result type calls chrome.tabs.update and chrome.windows.update`
   - `returns error response for invalid result`

3. **Tab Actions (switchToTab, navigateCurrentTab)**
   - `switchToTab activates tab and focuses window`
   - `navigateCurrentTab updates current tab URL`
   - `handles missing tabId gracefully`

4. **Error Scenarios** (per user decision - comprehensive error testing)
   - `malformed message with missing required fields returns error`
   - `Chrome API failure returns error response with message`
   - `invalid action returns appropriate response`

**Pattern for each test:**
```javascript
it('description', async () => {
  vi.resetModules();
  await import('../../background.js');

  // Setup Chrome mock data
  chromeMock.tabs.query.mockResolvedValue([...]);

  // Trigger message
  const sendResponse = vi.fn();
  const { asyncResponse } = chromeMock.runtime.onMessage.callListeners(
    { action: 'getSpotlightSuggestions', query: 'test', mode: 'current-tab' },
    { tab: { id: 42 } },
    sendResponse
  );

  // Wait for async response if needed
  if (asyncResponse) {
    await vi.waitFor(() => expect(sendResponse).toHaveBeenCalled(), { timeout: 2000 });
  }

  // Assert response
  expect(sendResponse).toHaveBeenCalledWith(expect.objectContaining({
    success: true,
    results: expect.any(Array)
  }));
});
```

**Important:**
- Use real timers (vi.useFakeTimers NOT called)
- Use vi.resetModules() before each dynamic import
- Use vi.waitFor() with timeout for async handlers (timeout: 2000ms for real timers)
- Import ResultType and SpotlightTabMode from shared/search-types.js
  </action>
  <verify>
Run `npm test` - new integration tests pass along with existing 197 tests.
  </verify>
  <done>
message-passing.test.js has 10+ tests covering search queries, result delivery, tab actions, and error scenarios. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create activation flow integration tests</name>
  <files>test/integration/activation-flow.test.js</files>
  <action>
Create test/integration/activation-flow.test.js covering INT-03:

**Test Structure:**
```javascript
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { chromeMock, resetChromeMocks } from '../mocks/chrome.js';

// Import setup for side effects
import './setup.js';
```

**Test Groups:**

1. **Activation Sequence (inject -> activate -> ready)**
   - `spotlightOpened message is handled by background` - verifies listener registered
   - `spotlightClosed message is handled by background` - cleanup path
   - `full lifecycle: open -> search -> close completes correctly`

2. **Double Activation Handling** (per user decision)
   - `second activation when spotlight already open sends close then open`
   - `rapid activations are handled without errors`

3. **Full Lifecycle (activate -> use -> close)** (per user decision)
   - `complete user session: open, search, select result, spotlight closes`
   - `escape/close during search properly cleans up state`

**Pattern:**
```javascript
it('full lifecycle: open -> search -> close', async () => {
  vi.resetModules();
  await import('../../background.js');

  // 1. Open spotlight
  const openResponse = vi.fn();
  chromeMock.runtime.onMessage.callListeners(
    { action: 'spotlightOpened' },
    { tab: { id: 42 } },
    openResponse
  );

  // 2. Perform search
  chromeMock.tabs.query.mockResolvedValue([]);
  const searchResponse = vi.fn();
  const { asyncResponse } = chromeMock.runtime.onMessage.callListeners(
    { action: 'getSpotlightSuggestions', query: 'test', mode: 'current-tab' },
    { tab: { id: 42 } },
    searchResponse
  );

  if (asyncResponse) {
    await vi.waitFor(() => expect(searchResponse).toHaveBeenCalled(), { timeout: 2000 });
  }

  // 3. Close spotlight
  const closeResponse = vi.fn();
  chromeMock.runtime.onMessage.callListeners(
    { action: 'spotlightClosed' },
    { tab: { id: 42 } },
    closeResponse
  );

  // Verify lifecycle completed
  expect(searchResponse.mock.calls[0][0].success).toBe(true);
});
```

**Note on DOM verification:** Per user decision, include DOM verification for overlay element. However, since overlay.js requires a full DOM environment and is complex, DOM tests may need JSDOM. If JSDOM is not installed, document this limitation and test the background-side message handling only. The E2E tests (Phase 5) will cover full DOM verification.
  </action>
  <verify>
Run `npm test` - activation flow tests pass along with all other tests.
  </verify>
  <done>
activation-flow.test.js has 5+ tests covering the full activation lifecycle. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `npm test` passes with all tests (197 existing + new integration tests)
2. INT-01 covered: Search query messages tested with various queries and modes
3. INT-02 covered: Result delivery tested with different result types and modes
4. INT-03 covered: Activation sequence and lifecycle tested
5. Error scenarios tested (malformed messages, API failures)
6. Tests use real timers (no vi.useFakeTimers)
7. Tests use callListeners() pattern (not direct handler calls)
</verification>

<success_criteria>
- message-passing.test.js covers:
  - Search query round-trip (INT-01)
  - Result delivery with correct Chrome API calls (INT-02)
  - Tab action messages
  - Error scenarios
- activation-flow.test.js covers:
  - Activation sequence (INT-03)
  - Double-activation handling
  - Full lifecycle (open -> use -> close)
- All tests pass with real timers
- Total test count increases by 15+ integration tests
</success_criteria>

<output>
After completion, create `.planning/phases/04-integration-tests/04-02-SUMMARY.md`
</output>
